{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2a7c73-0bfb-4cbd-896e-40ab3eb6ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "api = wandb.Api()\n",
    "entity, project = \"c2ai\", \"infonce-dialog\"  # set to your entity and project\n",
    "runs = api.runs(entity + \"/\" + project)\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "accepted_runs = []\n",
    "for i, run in enumerate(runs):\n",
    "    print(f\"\\n======= [{i+1}/{len(runs)}] Pulling {run.name} ========\")\n",
    "    df_run_valid= run.history(keys=[\"auc\", \"valid_loss\", \"mutual_info\"])\n",
    "    df_run_train= run.history(keys=[\"train_loss\"])\n",
    "    for file in filter(lambda x: x.name.endswith(\".pth\"), run.files()):\n",
    "        print(file.name)\n",
    "        accepted_runs.append(f\"bash finetune_pipeline.sh {run.id} ./data {file.name} | tee logs/{run.id}_{file.name}.log\")\n",
    "            \n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_dict = {\n",
    "        'best_valid_loss': df_run_valid['valid_loss'].min(),\n",
    "        'best_valid_mi': df_run_valid['mutual_info'].max(),\n",
    "        'best_auc': df_run_valid['auc'].max(),\n",
    "    }\n",
    "    print(summary_dict)\n",
    "    # summary_list.append(run.summary._json_dict)\n",
    "    summary_list.append(summary_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k,v in run.config.items()\n",
    "         if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "# print(f\"{run.config.keys()}\")\n",
    "# summary_keys = '\\n'.join(sorted(filter(lambda x: 'gradient' not in x, list(run.summary._json_dict.keys()))))\n",
    "# print(f\"{summary_keys}\")\n",
    "\n",
    "runs_df = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "    })\n",
    "\n",
    "runs_df.to_csv(\"checkpoints/c2ai.csv\")\n",
    "\n",
    "print(\"\\n============= Final filtered commands ==============\\n\")\n",
    "for cmd in accepted_runs:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ef82a-ba47-4af7-a2b2-7924c734a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
